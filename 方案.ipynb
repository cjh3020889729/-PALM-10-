{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 常规赛：PALM病理性近视预测 第10名方案\n",
    "\n",
    "本方案使用TNT模型进行训练与预测，在有限训练次数下，取得了较稳定的成绩：0.99515\n",
    "\n",
    "**采取的训练图像预处理方案：**\n",
    "\n",
    "* 随机垂直翻转\n",
    "* 随机角度翻转--0~20度\n",
    "* 缩放大小--（520，520）\n",
    "* 归一化--mean:[0.2, 0.3, 0.5], std:[0., 0., 0.]\n",
    "\n",
    "**采取的验证与预测图像预处理方案：**\n",
    "\n",
    "* 缩放大小--（520，520）\n",
    "* 归一化--mean:[0.2, 0.3, 0.5], std:[0., 0., 0.]\n",
    "\n",
    "**数据集划分比例：**0.8\n",
    "\n",
    "**TNT模型比较：**\n",
    "\n",
    "* 微调参数： tnt_s_patch16_224 得分 > tnt_b_patch16_224 得分\n",
    "\n",
    "**后期优化方向：**\n",
    "\n",
    "* 更合适的处理方式\n",
    "* patch大小与数量\n",
    "* 图片输入大小等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/data/data85133/常规赛：PALM病理性近视预测.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、导入相应的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import os\r\n",
    "import time\r\n",
    "from tqdm import tqdm\r\n",
    "import cv2 as cv\r\n",
    "import numpy as np\r\n",
    "import math\r\n",
    "\r\n",
    "import paddle\r\n",
    "from paddle import nn\r\n",
    "from paddle import optimizer\r\n",
    "from paddle import regularizer\r\n",
    "from paddle import metric\r\n",
    "from paddle.nn import loss\r\n",
    "from paddle.nn import Layer\r\n",
    "\r\n",
    "from paddle.io import Dataset, DataLoader\r\n",
    "from paddle.vision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、解析数据，制作Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image_path = '常规赛：PALM病理性近视预测/Train/fundus_image'\r\n",
    "Train_data = pd.read_excel('常规赛：PALM病理性近视预测/Train/Classification.xlsx')\r\n",
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Train_data)):\r\n",
    "    Train_data.iloc[i, 0] = os.path.join(Image_path, Train_data.iloc[i, 0])\r\n",
    "Train_data = Train_data.sample(frac=1.0).reset_index(drop=True)\r\n",
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test_data = []\r\n",
    "Test_path = '常规赛：PALM病理性近视预测/PALM-Testing400-Images'\r\n",
    "for _, _, files in os.walk(Test_path):\r\n",
    "    for i in files:\r\n",
    "        Test_data.append([i, 0])\r\n",
    "Test_data = np.asarray(Test_data)\r\n",
    "Test_data = pd.DataFrame(Test_data)\r\n",
    "Test_data = Test_data.sort_values(by=0, ascending=True).reset_index(drop=True)\r\n",
    "for i in range(len(Test_data)):\r\n",
    "    Test_data.iloc[i, 0] = os.path.join(Test_path, Test_data.iloc[i, 0])\r\n",
    "Test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\r\n",
    "    '''加载训练集\r\n",
    "        把数据加载函数拼进来\r\n",
    "    '''\r\n",
    "    def __init__(self, df, trans=None):\r\n",
    "        super(Train_Dataset, self).__init__()\r\n",
    "\r\n",
    "        self.df = df\r\n",
    "        \r\n",
    "        if trans is None:\r\n",
    "            self.trans = transforms.Compose([\r\n",
    "                transforms.RandomVerticalFlip(),\r\n",
    "                transforms.RandomRotation(20),\r\n",
    "                transforms.Resize(size=(520, 520)),\r\n",
    "                transforms.ToTensor(),\r\n",
    "                transforms.Normalize([0.2, 0.3, 0.5])\r\n",
    "            ])\r\n",
    "        else:\r\n",
    "            self.trans = trans\r\n",
    "\r\n",
    "        self.lens = len(df)\r\n",
    "\r\n",
    "    def __getitem__(self, indexs):\r\n",
    "\r\n",
    "        im_data, im_label = self._load_img_and_label(self.df, indexs)\r\n",
    "\r\n",
    "        im_data = self.trans(im_data)\r\n",
    "\r\n",
    "        return im_data, paddle.to_tensor(im_label)\r\n",
    "\r\n",
    "    def _load_img_and_label(self, df, index):\r\n",
    "        '''加载DF中的路径为图片和标签\r\n",
    "            df: 输入DF\r\n",
    "            index: 第几条数据\r\n",
    "            mode: 加载训练集数据模式还是测试集模式--区别在于是否转换数据域\r\n",
    "        '''\r\n",
    "        assert index < self.lens, \\\r\n",
    "            'please check the index, which has more than the dataset length!'\r\n",
    "\r\n",
    "        im_data = cv.imread(df.iloc[index, 0], cv.COLOR_BGR2RGB)  # 转为RGB数据\r\n",
    "\r\n",
    "        im_label = int(df.iloc[index, 1])  # 标签\r\n",
    "        \r\n",
    "        return np.asarray(im_data).astype('float32'), im_label\r\n",
    "    \r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.lens\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "class Test_Dataset(Dataset):\r\n",
    "    '''加载测试集\r\n",
    "        把数据加载函数拼进来\r\n",
    "    '''\r\n",
    "    def __init__(self, df, trans=None):\r\n",
    "        super(Test_Dataset, self).__init__()\r\n",
    "\r\n",
    "        self.df = df\r\n",
    "        \r\n",
    "        if trans is None:\r\n",
    "            self.trans = transforms.Compose([\r\n",
    "                transforms.Resize(size=(520, 520)),  # 保证迁移前后输入特征大小一致\r\n",
    "                transforms.ToTensor(),\r\n",
    "                transforms.Normalize([0.2, 0.3, 0.5])\r\n",
    "            ])\r\n",
    "        else:\r\n",
    "            self.trans = trans\r\n",
    "\r\n",
    "        self.lens = len(df)\r\n",
    "\r\n",
    "    def __getitem__(self, indexs):\r\n",
    "\r\n",
    "        im_data, im_label = self._load_img_and_label(self.df, indexs)\r\n",
    "\r\n",
    "        im_data = self.trans(im_data)\r\n",
    "\r\n",
    "        return im_data, paddle.to_tensor(im_label)\r\n",
    "\r\n",
    "    def _load_img_and_label(self, df, index):\r\n",
    "        '''加载DF中的路径为图片和标签\r\n",
    "            df: 输入DF\r\n",
    "            index: 第几条数据\r\n",
    "            mode: 加载训练集数据模式还是测试集模式--区别在于是否转换数据域\r\n",
    "        '''\r\n",
    "        assert index < self.lens, \\\r\n",
    "            'please check the index, which has more than the dataset length!'\r\n",
    "\r\n",
    "        im_data = cv.imread(df.iloc[index, 0], cv.COLOR_BGR2RGB)  # 转为RGB数据\r\n",
    "\r\n",
    "        im_label = int(df.iloc[index, 1])  # 标签\r\n",
    "        \r\n",
    "        return np.asarray(im_data).astype('float32'), im_label\r\n",
    "    \r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练参数-=dict\r\n",
    "Train_Paramdict = {\r\n",
    "    'data_length':len(Train_data),  # 数据长度\r\n",
    "    'train_frac':0.8,              # 训练集比例\r\n",
    "    'num_class':2,                  # 类别\r\n",
    "    'epoches':100,                   # 训练轮次\r\n",
    "    'batchsize':8,                 # 批量大小\r\n",
    "    'lr':0.0001,                      # 学习率\r\n",
    "    'l2':0.0005                    # L2正则化参数\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据集划分\r\n",
    "Fit_data  = Train_data.iloc[:int(Train_Paramdict['data_length']*Train_Paramdict['train_frac'])]\r\n",
    "Eval_data = Train_data.iloc[int(Train_Paramdict['data_length']*Train_Paramdict['train_frac']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据加载\r\n",
    "Fit_dataset = Train_Dataset(Fit_data)\r\n",
    "Eval_dataset = Test_Dataset(Eval_data)\r\n",
    "All_dataset = Train_Dataset(Train_data)\r\n",
    "\r\n",
    "Fit_dataloader = DataLoader(Fit_dataset, batch_size=Train_Paramdict['batchsize'], shuffle=True)\r\n",
    "Eval_dataloader = DataLoader(Eval_dataset, batch_size=Train_Paramdict['batchsize'])\r\n",
    "All_dataloader = DataLoader(All_dataset, batch_size=Train_Paramdict['batchsize'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、导入模型\n",
    "\n",
    "TNT模型在TNT.py中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建模型\r\n",
    "from TNT import tnt_s_patch16_224, tnt_b_patch16_224\r\n",
    "model = tnt_s_patch16_224(img_size=520, num_classes=2)\r\n",
    "model = paddle.Model(model)\r\n",
    "\r\n",
    "lr = optimizer.lr.LinearWarmup(\r\n",
    "    learning_rate=Train_Paramdict['lr'],\r\n",
    "    warmup_steps = 2000,\r\n",
    "    start_lr = 0, \r\n",
    "    end_lr = Train_Paramdict['lr']\r\n",
    ")\r\n",
    "\r\n",
    "O = optimizer.Adam(lr, parameters=model.parameters(), weight_decay=regularizer.L2Decay(Train_Paramdict['l2']))\r\n",
    "L = loss.CrossEntropyLoss()\r\n",
    "M = metric.Accuracy()\r\n",
    "\r\n",
    "model.prepare(O, L, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(\r\n",
    "    Fit_dataloader,\r\n",
    "    Eval_dataloader,\r\n",
    "    epochs=Train_Paramdict['epoches']\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据加载\r\n",
    "Test_dataset = Test_Dataset(Test_data)\r\n",
    "Test_dataloader = DataLoader(Test_dataset, batch_size=Train_Paramdict['batchsize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.预测结果并生成提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = model.predict(Test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = np.asarray(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "submit_result = []\r\n",
    "for i in results[0]:\r\n",
    "    i = paddle.to_tensor(i)\r\n",
    "    i = F.softmax(i)\r\n",
    "    result = i[:, 1]\r\n",
    "    submit_result += result.numpy().tolist()\r\n",
    "len(submit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_result = np.asarray(submit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test_data.iloc[:, 1] = submit_result\r\n",
    "Test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Submit_data = Test_data.copy()\r\n",
    "Submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Submit_data.columns = ['FileName', 'PM Risk']\r\n",
    "Submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Submit_data)):\r\n",
    "    Submit_data.iloc[i, 0] = Submit_data.iloc[i, 0][-9:]\r\n",
    "Submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Submit_data.to_csv('Classification_Results.csv', index=False, float_format=\"%.1f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
